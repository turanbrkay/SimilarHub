{
    "field_analysis": {
        "analytical_summary_role": "`analytical_summary` alanı, dizinin genel vizyonunu, başlıca temalarını, anlatı tarzını ve hedef kitlesini yüksek seviyede özetleyen kompakt bir metindir. Örneklerde gördüğümüz kadarıyla genellikle 3-5 cümleden oluşan bu alan, dizinin tematik derinliğini (örneğin 'political intrigue', 'supernatural threats', 'moral ambiguity'), tone'unu (örneğin 'gritty', 'dark', 'psychological') ve karakter dinamiklerini genel hatlarıyla açıklar. Bu alan, dizinin essence'ını ve benzersiz selling point'lerini yoğunlaştırılmış bir formda sunar ve genellikle 150-250 kelime arasındadır.",
        "spoiler_rich_plot_summary_role": "`spoiler_rich_plot_summary` alanı son derece detaylı ve spoiler içeren bir plot özetidir. Örneklerde 400-600 kelime uzunluğunda olduğunu gözlemledik. Bu alan, dizinin season-by-season ilerleyişini, major plot twist'leri (örneğin Red Wedding, Night King'in ölümü), karakter arc'larını ve final çözümünü sahneler bazında açıklar. Narrative progression'ı kronolojik olarak takip eder ve key event'leri (örneğin 'death of Ned Stark', 'fall of Cersei') spesifik olarak listeler. Bu alan, storyline similarity aramaları için en zengin detayı sağlar ancak uzunluğu nedeniyle embedding'de dominant olabilir.",
        "categorized_keywords_role": "`categorized_keywords` alanı yapılandırılmış ve kategorize edilmiş keyword listeleridir. Her kategori (themes, mood_and_tone, genre_and_tropes, setting, character_archetypes, narrative_style, target_audience, detail_plot vb.) kendi içinde 5-15 adet keyword içerir. Bu yapı, free text'ten farklı olarak discrete feature'lar gibi çalışır ve yüksek discriminative power'a sahiptir. Örneklerde toplam 50-80 unique keyword gördük. Bu alan tag-based benzerlik aramaları için ideal olup, kullanıcının 'dark supernatural mystery with anti-hero' gibi spesifik keyword kombinasyonlarını aramasına olanak tanır.",
        "observations_from_samples": "Örnek dosyalardan yaptığımız gözlemler şunlardır: (1) `analytical_summary` her zaman 3-5 paragraftan oluşan, yoğunlaştırılmış bir overview sağlıyor ve genellikle 150-250 kelime. (2) `spoiler_rich_plot_summary` çok daha uzun (400-600+ kelime) ve extremely detailed, season-wide event'leri açıklıyor. (3) `categorized_keywords` çok yapılandırılmış ve tag-like, toplam 60-90 adet keyword içeriyor ve yüksek precision ile aranabilir. (4) Üç alan arasında semantic overlap var ('dark', 'betrayal', 'psychological' gibi terimler hem summary'de hem keywords'de geçiyor) ama her biri farklı granularity level'ında çalışıyor. (5) `spoiler_rich_plot_summary`'nin uzunluğu diğer iki alandan 2-3 kat daha fazla, bu nedenle concatenation yapılırsa bu alan embedding'i dominate edebilir."
    },
    "vectorization_strategy": {
        "multi_vector_vs_single_vector_comparison": "Multi-vector yaklaşımında her dizi için üç ayrı embedding oluşturulur: `v_analytical`, `v_plot`, `v_keywords`. Query sırasında kullanıcı sorgusu da üç farklı perspektiften embed edilir ve her field için ayrı cosine similarity hesaplanır. Final score weighted combination ile bulunur: `score = w_a * sim(q, v_analytical) + w_p * sim(q, v_plot) + w_k * sim(q, v_keywords)`. Bu yaklaşımın장avantajları: (1) Her field'ın contribution'ı explicit olarak kontrol edilebilir, (2) Intent-based weighting mümkün olur (plot-focused query için w_p artırılır), (3) Debugging ve tuning kolaydır, (4) Field-specific query optimization yapılabilir. Dezavantajları: (1) Üç kat daha fazla storage, (2) Query time'da üç embedding computation, (3) Vector database'de indexing complexity. Single-vector yaklaşımında tüm alanlar concatenate edilip tek bir embedding oluşturulur. Avantajları: (1) Minimal storage ve computation, (2) Basit implementation. Dezavantajları: (1) `spoiler_rich_plot_summary`'nin uzunluğu (400-600 kelime) embedding'i dominate eder, analytical_summary (150-250 kelime) ve keywords (60-90 tag) signal'ı dilute olur, (2) Field-specific weighting imkansız hale gelir, (3) 'I want a show with dark themes and political intrigue' gibi high-level query'ler plot detail'lerinin gürültüsünde kaybolabilir, (4) Kullanıcının explicit field preference'larını (sadece keyword match, sadece theme similarity) karşılamak mümkün olmaz.",
        "recommended_strategy": "multi_vector",
        "recommended_strategy_justification": "Multi-vector stratejisini öneriyoruz çünkü kullanıcı açıkça 'explicit coefficients to each field' ve 'weighted combination' istiyor. Sample data'dan gördüğümüz üzere: (1) `spoiler_rich_plot_summary` 2-3 kat daha uzun olduğu için single-vector'de diğer field'ları ezecek, (2) `categorized_keywords` tag-like yapısı nedeniyle farklı bir semantic space'te çalışıyor ve ayrı bir vector'de tutulmalı, (3) Kullanıcı query'leri farklı intent'lere sahip olabilir (bazıları plot-based, bazıları mood-based, bazıları pure keyword-based) ve bu intent'lere göre weight'leri adjust edebilmek kritik öneme sahip. (4) RAG pipeline'da retrieval quality'yi optimize etmek için field-level tuning şart. Örneğin kullanıcı 'I want a dark psychological thriller with mind games' dediğinde, `categorized_keywords` ve `analytical_summary` yüksek weight almalı, detaylı plot summary düşük weight almalı. Multi-vector bu flexibility'yi sağlar. Alternatif olarak hybrid yaklaşım da düşünülebilir: analytical_summary + keywords birleştirilerek tek vector, spoiler_rich_plot_summary ayrı vector. Bu şekilde iki vector'e iner, storage azalır ama hala field-based weighting mümkün olur. Ancak tam flexibility için üç ayrı vector en ideal çözümdür."
    },
    "weighting_scheme": {
        "global_weights": {
            "w_analytical_summary": 0.40,
            "w_spoiler_rich_plot_summary": 0.25,
            "w_categorized_keywords": 0.35
        },
        "intent_based_profiles": {
            "plot_based": {
                "w_analytical_summary": 0.20,
                "w_spoiler_rich_plot_summary": 0.60,
                "w_categorized_keywords": 0.20,
                "rationale": "Plot-based query'lerde kullanıcı storyline detaylarıyla ilgilenir ('dizinin hikayesi şöyle şöyle gelişiyor', 'final twist neydi', 'karakter journey'leri nasıl'). Bu durumda `spoiler_rich_plot_summary` field'ı dominant olmalı çünkü event-by-event progression'ı ve plot twist'leri içeriyor. `analytical_summary` ve `categorized_keywords` düşük weight alır çünkü high-level theme veya tag'ler plot detaylarını capture edemez. Örnek query: 'Find me shows where the protagonist has a tragic fall and betrayal by close allies'."
            },
            "theme_mood_based": {
                "w_analytical_summary": 0.50,
                "w_spoiler_rich_plot_summary": 0.10,
                "w_categorized_keywords": 0.40,
                "rationale": "Theme ve mood-based query'lerde kullanıcı dizinin atmosphere'ı, vibe'ı ve tematik derinliğiyle ilgilenir. `analytical_summary` bu tür bilgileri compact bir formda sunar (örneğin 'gritty realism', 'moral ambiguity', 'psychological depth'). `categorized_keywords` içindeki `themes` ve `mood_and_tone` kategorileri de bu query'lere çok iyi match eder. `spoiler_rich_plot_summary` ise plot detaylarına odaklandığı için bu intent'te noise yaratır. Örnek query: 'I want a dark, atmospheric show with themes of betrayal and moral complexity'."
            },
            "keyword_topic_based": {
                "w_analytical_summary": 0.15,
                "w_spoiler_rich_plot_summary": 0.10,
                "w_categorized_keywords": 0.75,
                "rationale": "Keyword veya topic-based query'lerde kullanıcı çok spesifik motif'ler, trope'lar veya feature'lar arıyor ('supernatural elements', 'time travel', 'anti-hero', 'ensemble cast'). `categorized_keywords` field'ı bu tür discrete concept'leri tag-like format'ta sunduğu için en yüksek discriminative power'a sahip. Diğer iki field free-flowing text olduğu için keyword matching'de daha az precise. Örnek query: 'Shows with dragons, political intrigue, and ensemble cast in a medieval fantasy setting'."
            },
            "mixed": {
                "w_analytical_summary": 0.40,
                "w_spoiler_rich_plot_summary": 0.25,
                "w_categorized_keywords": 0.35,
                "rationale": "Mixed intent veya belirsiz query'lerde (örneğin 'recommend me something like Breaking Bad') balanced bir weight distribution kullanırız. `analytical_summary` en yüksek weight'i alır çünkü dizinin overall essence'ını en iyi capture eder ve theme + tone + character dynamics'i kombine eder. `categorized_keywords` genre, tropes ve setting bilgisiyle ikinci sırada. `spoiler_rich_plot_summary` en düşük weight'i alır çünkü plot detail'leri generic similarity aramasında çok specific olabilir ve false negative'lere yol açabilir. Bu default profile olarak kullanılır."
            }
        }
    },
    "similarity_and_search_design": {
        "query_embedding_design": "Kullanıcının natural language query'sini embedding'e dönüştürmek için iki yaklaşım mümkündür. Basit yaklaşımda, kullanıcının query'si aynen üç kez embed edilir: `q_analytical = embed(user_query)`, `q_plot = embed(user_query)`, `q_keywords = embed(user_query)`. Bu yaklaşım straightforward'dır ancak her field'ın semantic space'ine optimize değildir. Gelişmiş yaklaşımda, küçük bir LLM adımı ile query üç specialized sub-query'ye dönüştürülür. Örneğin kullanıcı 'I want a dark show about family conflict and power struggle' derse, LLM şöyle transform edebilir: (1) `q_analytical_text`: 'A show exploring dark themes of family conflict and power struggle with complex character dynamics', (2) `q_plot_text`: 'A story where families fight for power leading to tragic consequences and betrayals', (3) `q_keywords_text`: 'dark, family, power-struggle, betrayal, political-drama'. Her bir specialized text embed edilerek field-specific query vector'ları oluşturulur. Bu yaklaşım daha iyi semantic alignment sağlar. Ayrıca intent classification yapılabilir: query önce 'plot_based', 'theme_mood_based', 'keyword_topic_based' veya 'mixed' olarak classify edilir ve buna göre weight profile seçilir. Bu classification basit keyword matching veya küçük bir classifier model ile yapılabilir.",
        "similarity_formula_and_ranking": "Her dizi için final similarity score şu formül ile hesaplanır:\n\n```python\ndef compute_similarity(query_vectors, movie_vectors, weights):\n    # query_vectors = {'analytical': q_a, 'plot': q_p, 'keywords': q_k}\n    # movie_vectors = {'analytical': v_a, 'plot': v_p, 'keywords': v_k}\n    # weights = {'w_a': 0.4, 'w_p': 0.25, 'w_k': 0.35}\n    \n    sim_analytical = cosine_similarity(query_vectors['analytical'], movie_vectors['analytical'])\n    sim_plot = cosine_similarity(query_vectors['plot'], movie_vectors['plot'])\n    sim_keywords = cosine_similarity(query_vectors['keywords'], movie_vectors['keywords'])\n    \n    final_score = (weights['w_a'] * sim_analytical + \n                   weights['w_p'] * sim_plot + \n                   weights['w_k'] * sim_keywords)\n    \n    return final_score\n\n# Tüm diziler için score hesapla\nscores = []\nfor movie in movie_database:\n    score = compute_similarity(query_vectors, movie.vectors, selected_weights)\n    scores.append((movie.id, score))\n\n# Score'a göre descending sırala\nranked_movies = sorted(scores, key=lambda x: x[1], reverse=True)\ntop_k_movies = ranked_movies[:k]  # En yüksek k tane döndür\n```\n\nAlternatif olarak, normalize edilmiş score için weighted average yerine weighted sum sonrası normalization yapılabilir veya min-max scaling uygulanabilir. Ayrıca threshold-based filtering eklenebilir: sadece final_score > 0.7 olan diziler döndürülür.",
        "how_users_search_in_own_words": "Kullanıcılar kendi kelimeleriyle arama yaparken doğal dilde sorgular girerler: 'I'm looking for a show like Breaking Bad but with more action', 'dark psychological thrillers with complex characters', 'family drama set in medieval times'. Bu query'ler önce intent classification'dan geçirilir (yukarıda bahsedilen 4 intent kategorisinden biri seçilir). Ardından query, multi-field embedding için ya direkt üç kez embed edilir ya da LLM ile field-specific sub-query'lere transform edilir. Embedding model (örneğin Sentence-BERT, OpenAI text-embedding-3, Cohere embed v3) kullanılarak her sub-query vector'e dönüştürülür. Vector database'de (Pinecone, Weaviate, Qdrant, Milvus veya basit FAISS) her dizi için stored olan üç vector ile query vector'ları karşılaştırılır. Cosine similarity hesaplanır ve weighted combination'la final score bulunur. Top-k candidate döndürülür. Kullanıcı ayrıca filter da ekleyebilir (örneğin 'release year > 2010', 'genre = Drama') ve bunlar post-filtering veya pre-filtering olarak uygulanır."
    },
    "rag_pipeline_design": {
        "indexing_strategy": "Multi-vector indexing için iki yaklaşım vardır. Birinci yaklaşımda, her dizi için üç ayrı vector üç farklı collection/index'te saklanır: `analytical_index`, `plot_index`, `keywords_index`. Her index kendi namespace'inde tutulur ve query sırasında üç parallel search yapılır. Vector database'ler genellikle multiple collection'ı destekler (Pinecone namespace, Weaviate class, Qdrant collection). Her collection'da movie_id ile vector mapping yapılır. İkinci yaklaşımda, tüm vector'lar tek bir collection'da saklanır ancak metadata field'ı ile ayırt edilir: her entry `{movie_id, field_type: 'analytical'|'plot'|'keywords', vector}` şeklinde tutulur. Query sırasında metadata filter ile field_type'a göre arama yapılır. Bu yaklaşım daha basit ama query performance'ı biraz düşük olabilir. Üçüncü bir yaklaşım ise compound document kullanmaktır: her dizi bir document olarak saklanır ve document içinde üç ayrı vector field bulunur. Vector database'in multi-vector support'u varsa (örneğin Weaviate'in multi-vector modules) bu ideal çözümdür. Indexing sırasında batch processing önerilir: tüm diziler iterate edilir, her dizi için LLM output'larından üç field extract edilir, embedding model ile üç vector üretilir, vector database'e batch insert yapılır. Embedding generation parallelized edilebilir (multi-threading/async) ve caching uygulanabilir (aynı text'i tekrar embed etmemek için).",
        "retrieval_strategy": "Query time'da retrieval şu şekilde çalışır: (1) Kullanıcının natural language query'si alınır. (2) Intent classification yapılır (optional ama önerilen) ve buna göre weight profile seçilir (plot_based, theme_mood_based, keyword_topic_based, mixed). (3) Query, field-specific sub-query'lere transform edilir (LLM ile veya direkt kullanılır). (4) Her sub-query embed edilir: `q_analytical_vec`, `q_plot_vec`, `q_keywords_vec`. (5) Vector database'de her field için ayrı ayrı similarity search yapılır. Her search top-N candidate döndürür (N genellikle 50-100). (6) Candidate'lar intersect edilir veya union alınır (union daha inclusive, intersect daha precise). (7) Her candidate için üç field similarity score hesaplanır. (8) Weighted combination formülü uygulanarak final score bulunur. (9) Final score'a göre descending sort edilir. (10) Top-K (örneğin K=10) result döndürülür. Performance optimization için approximate nearest neighbor (ANN) algoritmaları kullanılır (HNSW, IVF, Product Quantization). Hybrid search de düşünülebilir: vector similarity + keyword matching (BM25) combination. Ayrıca re-ranking stage eklenebilir: ilk 50 candidate vector similarity ile bulunur, ardından LLM ile re-rank edilir (daha pahalı ama daha accurate).",
        "generation_and_explanation_strategy": "Retrieval sonrası RAG pipeline'ın generation aşamasında, retrieved diziler LLM'e context olarak verilir ve kullanıcıya personalized recommendation ve explanation üretilir. Prompt şöyle olabilir:\n\n```\nUser Query: {user_query}\n\nTop Retrieved Shows:\n1. {show1_title}: {show1_analytical_summary}\n   - Similarity Scores: analytical={score_a1}, plot={score_p1}, keywords={score_k1}\n   - Final Score: {final_score1}\n\n2. {show2_title}: {show2_analytical_summary}\n   - Similarity Scores: analytical={score_a2}, plot={score_p2}, keywords={score_k2}\n   - Final Score: {final_score2}\n\n...\n\nTask: Based on the user's query and the retrieved shows, generate:\n1. A brief explanation of why these shows match the user's request.\n2. Highlight the specific aspects (themes, plot elements, mood) that make each show relevant.\n3. Rank the top 3 shows and explain the ranking.\n4. Suggest any nuances or differences the user should be aware of.\n```\n\nLLM (GPT-4, Claude, Gemini) bu prompt ile detailed, personalized recommendation üretir. Explanation'da field-level similarity score'lar kullanılarak justification yapılır: 'This show has a very high keyword match (0.92) because it shares the dark, psychological themes you're looking for.' Ayrıca comparison yapılabilir: 'Show A is more plot-driven while Show B focuses on character depth.' Chain-of-thought prompting ile LLM'e reasoning adımları yaptırılabilir. Final output user-friendly format'ta sunulur (markdown, bullet points, conversational tone)."
    },
    "implementation_notes_tr": "Implementation sırasında dikkat edilmesi gerekenler: (1) Embedding model seçimi kritiktir. Sentence-BERT (all-MiniLM-L6-v2, all-mpnet-base-v2) hızlı ve lightweight. OpenAI text-embedding-3-small/large daha güçlü ama API cost var. Domain-specific fine-tuning düşünülebilir (TV show description'ları üzerinde contrastive learning). (2) Vector dimension trade-off: 384-dim (MiniLM) storage-efficient, 768-dim (MPNet) daha expressive, 1536-dim (OpenAI) en güçlü ama storage 4x fazla. (3) Batch size ve parallelization: embedding generation'ı batch halinde yapın (batch_size=32-128), API rate limit'lere dikkat edin. (4) Caching strategy: aynı field text'leri için embedding'leri cache'leyin, özellikle keywords gibi sık tekrar eden pattern'ler için. (5) Vector database seçimi: Pinecone managed ve kolay, Qdrant açık kaynak ve performanslı, FAISS local ve ücretsiz ama scalability sınırlı. (6) Weight tuning: A/B testing ile farklı weight profile'ları deneyin, user feedback toplayın, click-through rate ve dwell time metric'lerini optimize edin. (7) Query processing: user query'leri çok varyasyonlu olabilir (typo, slang, abbreviation), spell-check ve normalization uygulayın. (8) Cold start problem: yeni eklenen diziler için embedding'ler hemen generate edilmeli, async worker queue kullanın. (9) Monitoring: similarity score distribution'ı, retrieval latency, embedding generation time monitor edin. (10) Fallback mechanism: vector search sonuç döndürmezse (çok spesifik query) fallback olarak keyword-based search veya genre-based filtering uygulayın."
}