#!/usr/bin/env python3
"""
SimilarHub Data Import Script
Bu script TMDB_tv_dataset.csv dosyasÄ±ndan TV dizi verilerini okuyup PostgreSQL veritabanÄ±na yÃ¼kler.
"""

import os
import csv
import json
import psycopg2
import psycopg2.extras
from datetime import datetime
from dotenv import load_dotenv

# Environment deÄŸiÅŸkenlerini yÃ¼kle
load_dotenv()

DATABASE_URL = os.getenv("DATABASE_URL")
CSV_FILE = "/app/database/TMDB_tv_dataset.csv"
BATCH_SIZE = 1000  # Her seferde kaÃ§ kayÄ±t insert edeceÄŸimiz

def parse_year(date_str):
    """Tarih string'inden yÄ±l bilgisini Ã§Ä±karÄ±r"""
    if not date_str or date_str == "":
        return None
    try:
        return int(date_str.split("-")[0])
    except:
        return None

def parse_json_field(field_str):
    """String JSON'u liste'ye dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r"""
    if not field_str or field_str == "":
        return []
    try:
        # EÄŸer zaten liste ise
        if isinstance(field_str, list):
            return field_str
        # String'i parse et
        items = [item.strip() for item in field_str.split(",")]
        return items
    except:
        return []

def clean_genres(genres_str):
    """Genres string'ini JSON array'e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r"""
    if not genres_str or genres_str == "":
        return json.dumps([])
    
    try:
        # "Sci-Fi & Fantasy, Drama, Action & Adventure" -> ["Sci-Fi & Fantasy", "Drama", "Action & Adventure"]
        genres = [g.strip() for g in genres_str.split(",")]
        return json.dumps(genres)
    except:
        return json.dumps([])

def import_tv_shows():
    """CSV dosyasÄ±ndan TV dizilerini veritabanÄ±na import eder"""
    
    if not DATABASE_URL:
        print("âŒ HATA: DATABASE_URL environment deÄŸiÅŸkeni tanÄ±mlÄ± deÄŸil!")
        print("LÃ¼tfen .env dosyasÄ±nÄ± kontrol edin.")
        return
    
    if not os.path.exists(CSV_FILE):
        print(f"âŒ HATA: CSV dosyasÄ± bulunamadÄ±: {CSV_FILE}")
        return
    
    print("=" * 80)
    print("SimilarHub - TV Dizileri Veri Import Scripti")
    print("=" * 80)
    print(f"ðŸ“ CSV DosyasÄ±: {CSV_FILE}")
    print(f"ðŸ—„ï¸  VeritabanÄ±: {DATABASE_URL.split('@')[1] if '@' in DATABASE_URL else 'localhost'}")
    print()
    
    # VeritabanÄ±na baÄŸlan
    try:
        conn = psycopg2.connect(DATABASE_URL)
        cur = conn.cursor()
        print("âœ… VeritabanÄ± baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±")
    except Exception as e:
        print(f"âŒ VeritabanÄ± baÄŸlantÄ± hatasÄ±: {e}")
        return
    
    # VeritabanÄ±nÄ± temizle (isteÄŸe baÄŸlÄ±)
    print("\nâš ï¸  Mevcut TV dizileri siliniyor...")
    try:
        cur.execute("DELETE FROM media_items WHERE source_type = 'tv'")
        conn.commit()
        print("âœ… VeritabanÄ± temizlendi")
    except Exception as e:
        print(f"âš ï¸  Temizleme hatasÄ± (devam ediliyor): {e}")
        conn.rollback()
    
    # CSV dosyasÄ±nÄ± oku ve import et
    print(f"\nðŸ“– CSV dosyasÄ± okunuyor...")
    
    batch = []
    total_processed = 0
    total_inserted = 0
    errors = 0
    
    try:
        with open(CSV_FILE, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            
            for row in reader:
                total_processed += 1
                
                try:
                    # Veriyi hazÄ±rla
                    tv_show = {
                        'id': int(row['id']),
                        'title': row['name'][:500] if row.get('name') else 'Unknown',
                        'poster_path': row.get('poster_path', ''),
                        'year': parse_year(row.get('first_air_date', '')),
                        'overview': row.get('overview', ''),
                        'genres': clean_genres(row.get('genres', '')),
                        'source_type': 'tv',
                        'original_language': row.get('original_language', 'en'),
                        'popularity': float(row.get('popularity', 0)) if row.get('popularity') else 0,
                        'embeddings': json.dumps({})  # Embeddings ÅŸimdilik boÅŸ
                    }
                    
                    batch.append(tv_show)
                    
                    # Batch dolduysa veritabanÄ±na yaz
                    if len(batch) >= BATCH_SIZE:
                        inserted = insert_batch(cur, batch)
                        total_inserted += inserted
                        conn.commit()
                        batch = []
                        
                        # Ä°lerleme gÃ¶ster
                        if total_processed % 10000 == 0:
                            print(f"  ðŸ“Š Ä°ÅŸlenen: {total_processed:,} | Eklenen: {total_inserted:,} | Hata: {errors}")
                
                except Exception as e:
                    errors += 1
                    if errors < 10:  # Ä°lk 10 hatayÄ± gÃ¶ster
                        print(f"  âš ï¸  SatÄ±r {total_processed} hatasÄ±: {e}")
                    continue
            
            # Kalan kayÄ±tlarÄ± ekle
            if batch:
                inserted = insert_batch(cur, batch)
                total_inserted += inserted
                conn.commit()
        
        print("\n" + "=" * 80)
        print("âœ… IMPORT TAMAMLANDI!")
        print("=" * 80)
        print(f"ðŸ“Š Toplam iÅŸlenen kayÄ±t: {total_processed:,}")
        print(f"âœ… BaÅŸarÄ±yla eklenen: {total_inserted:,}")
        print(f"âš ï¸  Hata sayÄ±sÄ±: {errors}")
        print()
        
        # VeritabanÄ± istatistiklerini gÃ¶ster
        print("ðŸ“ˆ VeritabanÄ± Ä°statistikleri:")
        cur.execute("SELECT COUNT(*) FROM media_items WHERE source_type = 'tv'")
        tv_count = cur.fetchone()[0]
        print(f"  â€¢ Toplam TV dizisi: {tv_count:,}")
        
        cur.execute("SELECT COUNT(*) FROM media_items WHERE source_type = 'tv' AND original_language = 'en'")
        en_count = cur.fetchone()[0]
        print(f"  â€¢ Ä°ngilizce diziler: {en_count:,}")
        
        cur.execute("SELECT title, year, popularity FROM media_items WHERE source_type = 'tv' ORDER BY popularity DESC LIMIT 5")
        top_shows = cur.fetchall()
        print(f"\nðŸ”¥ En PopÃ¼ler 5 Dizi:")
        for i, (title, year, pop) in enumerate(top_shows, 1):
            print(f"  {i}. {title} ({year}) - PopÃ¼lerlik: {pop:.2f}")
        
    except Exception as e:
        print(f"\nâŒ HATA: {e}")
        conn.rollback()
    
    finally:
        cur.close()
        conn.close()
        print("\nâœ… VeritabanÄ± baÄŸlantÄ±sÄ± kapatÄ±ldÄ±")

def insert_batch(cursor, batch):
    """Batch insert iÅŸlemi yapar"""
    if not batch:
        return 0
    
    insert_query = """
        INSERT INTO media_items (id, title, poster_path, year, overview, genres, source_type, original_language, popularity, embeddings)
        VALUES (%(id)s, %(title)s, %(poster_path)s, %(year)s, %(overview)s, %(genres)s, %(source_type)s, %(original_language)s, %(popularity)s, %(embeddings)s)
        ON CONFLICT (id) DO UPDATE SET
            title = EXCLUDED.title,
            poster_path = EXCLUDED.poster_path,
            year = EXCLUDED.year,
            overview = EXCLUDED.overview,
            genres = EXCLUDED.genres,
            popularity = EXCLUDED.popularity,
            updated_at = CURRENT_TIMESTAMP
    """
    
    try:
        psycopg2.extras.execute_batch(cursor, insert_query, batch)
        return len(batch)
    except Exception as e:
        print(f"  âŒ Batch insert hatasÄ±: {e}")
        return 0

if __name__ == "__main__":
    print()
    import_tv_shows()
    print()
    print("ðŸ’¡ Ä°pucu: UygulamayÄ± yeniden baÅŸlatÄ±n: docker-compose restart backend")
    print()
